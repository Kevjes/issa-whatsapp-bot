import { AIResponse, AIProviderConfig, OpenAIRequest, OpenAIResponse, DeepSeekRequest, DeepSeekResponse, ConversationMessage } from '../types';
import { config } from '../config';
import { logger } from '../utils/logger';
import { IHttpClient } from '../core/interfaces/IHttpClient';

export class AIService {
  private httpClient: IHttpClient;
  private aiConfig: AIProviderConfig;

  constructor(httpClient: IHttpClient) {
    this.httpClient = httpClient;
    this.aiConfig = {
      provider: config.ai.provider,
      apiKey: config.ai.apiKey,
      model: config.ai.model,
      baseUrl: config.ai.baseUrl
    };

    logger.info('AI Service initialized', {
      provider: this.aiConfig.provider,
      model: this.aiConfig.model,
      hasApiKey: !!this.aiConfig.apiKey
    });
  }

  private getDefaultModel(): string {
    if (config.ai.provider === 'openai') return 'gpt-3.5-turbo';
    if (config.ai.provider === 'gemini') return 'gemini-2.5-flash';
    return 'deepseek-chat';
  }

  /**
   * G√©n√©rer une r√©ponse avec l'IA configur√©e
   */
  async generateResponse(
    userMessage: string,
    conversationHistory: ConversationMessage[] = [],
    systemPrompt?: string
  ): Promise<AIResponse> {
    try {
      if (!this.aiConfig.apiKey) {
        throw new Error(`Cl√© API manquante pour ${this.aiConfig.provider}`);
      }

      // Construire les messages pour l'IA
      const messages = this.buildMessages(userMessage, conversationHistory, systemPrompt);

      let aiResponse: AIResponse;
      if (this.aiConfig.provider === 'openai') {
        aiResponse = await this.callOpenAI(messages);
      } else if (this.aiConfig.provider === 'gemini') {
        aiResponse = await this.callGemini(messages);
      } else {
        aiResponse = await this.callDeepSeek(messages);
      }

      // Valider la r√©ponse
      if (aiResponse.success && aiResponse.content) {
        const validation = this.validateResponse(aiResponse.content, systemPrompt || '');

        if (!validation.isValid) {
          logger.warn('R√©ponse IA rejet√©e par validation', {
            reason: validation.reason,
            responsePreview: aiResponse.content.substring(0, 100)
          });

          // Retourner une r√©ponse s√©curis√©e
          return {
            success: true,
            content: `Je ne dispose pas de cette information dans ma base de connaissances actuelle.

üìç Pour obtenir une r√©ponse pr√©cise et officielle, je vous invite √† :

üî∏ Consulter notre site web : www.roitakaful.com
üî∏ Contacter notre service client : +237 691 100 575
üî∏ Nous √©crire : contact@roitakaful.com

Je reste √† votre disposition pour toute question sur nos produits et services document√©s !`,
            provider: this.aiConfig.provider
          };
        }
      }

      return aiResponse;

    } catch (error) {
      logger.error('Erreur lors de la g√©n√©ration de r√©ponse IA', {
        provider: this.aiConfig.provider,
        error: error instanceof Error ? error.message : 'Unknown error',
        userMessage: userMessage.substring(0, 100)
      });

      return {
        success: false,
        error: `Erreur ${this.aiConfig.provider}: ${error instanceof Error ? error.message : 'Unknown error'}`,
        provider: this.aiConfig.provider
      };
    }
  }

  /**
   * Construire les messages pour l'IA
   */
  private buildMessages(
    userMessage: string,
    conversationHistory: ConversationMessage[],
    systemPrompt?: string
  ): Array<{ role: 'system' | 'user' | 'assistant'; content: string }> {
    const messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }> = [];

    // Message syst√®me
    if (systemPrompt) {
      messages.push({
        role: 'system',
        content: systemPrompt
      });
    }

    // Historique de conversation (limit√© aux 10 derniers √©changes pour √©viter de surcharger)
    const recentHistory = conversationHistory.slice(-20);
    for (const msg of recentHistory) {
      messages.push({
        role: msg.messageType === 'user' ? 'user' : 'assistant',
        content: msg.content
      });
    }

    // Message actuel de l'utilisateur
    messages.push({
      role: 'user',
      content: userMessage
    });

    return messages;
  }

  /**
   * Appeler l'API OpenAI
   */
  private async callOpenAI(messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }>): Promise<AIResponse> {
    try {
      const requestData: OpenAIRequest = {
        model: this.aiConfig.model,
        messages,
        temperature: 0.7,
        max_tokens: 1000
      };

      // Note: baseURL and headers are configured at the HTTP client level
      const response = await this.httpClient.post('/chat/completions', requestData);

      const data = response.data as OpenAIResponse;

      if (data.choices && data.choices.length > 0) {
        return {
          success: true,
          content: data.choices[0].message.content,
          provider: 'openai',
          tokensUsed: data.usage?.total_tokens
        };
      } else {
        throw new Error('Aucune r√©ponse re√ßue d\'OpenAI');
      }

    } catch (error: unknown) {
      logger.error('Erreur API OpenAI', { error });
      throw error;
    }
  }

  /**
   * Appeler l'API DeepSeek
   */
  private async callDeepSeek(messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }>): Promise<AIResponse> {
    try {
      const requestData: DeepSeekRequest = {
        model: this.aiConfig.model,
        messages,
        temperature: 0.7,
        max_tokens: 1000,
        stream: false
      };

      // Note: baseURL and headers are configured at the HTTP client level
      const response = await this.httpClient.post('/chat/completions', requestData);

      const data = response.data as DeepSeekResponse;

      if (data.choices && data.choices.length > 0) {
        return {
          success: true,
          content: data.choices[0].message.content,
          provider: 'deepseek',
          tokensUsed: data.usage?.total_tokens
        };
      } else {
        throw new Error('Aucune r√©ponse re√ßue de DeepSeek');
      }

    } catch (error: unknown) {
      logger.error('Erreur API DeepSeek', { error });
      throw error;
    }
  }

  /**
   * Appeler l'API Google Gemini
   */
  private async callGemini(messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }>): Promise<AIResponse> {
    try {
      // Gemini utilise un format diff√©rent: systemInstruction s√©par√© + contents
      const systemMessage = messages.find(m => m.role === 'system');
      const conversationMessages = messages.filter(m => m.role !== 'system');

      // Convertir les messages au format Gemini
      const contents = conversationMessages.map(msg => ({
        role: msg.role === 'assistant' ? 'model' : 'user',
        parts: [{ text: msg.content }]
      }));

      const requestData: any = {
        contents,
        generationConfig: {
          temperature: 0.7,
          maxOutputTokens: 1000,
          topP: 0.95
        }
      };

      // Ajouter systemInstruction si pr√©sent
      if (systemMessage) {
        requestData.systemInstruction = {
          parts: [{ text: systemMessage.content }]
        };
      }

      // Endpoint Gemini (sans API key dans l'URL)
      const endpoint = `/models/${this.aiConfig.model}:generateContent`;

      // Gemini n√©cessite l'API key dans le header x-goog-api-key
      const response = await this.httpClient.post(endpoint, requestData, {
        headers: {
          'x-goog-api-key': this.aiConfig.apiKey,
          'Content-Type': 'application/json'
        }
      });

      const data = response.data as any;

      if (data.candidates && data.candidates.length > 0) {
        const candidate = data.candidates[0];
        const content = candidate.content?.parts?.[0]?.text;

        if (content) {
          return {
            success: true,
            content,
            provider: 'gemini',
            tokensUsed: data.usageMetadata?.totalTokenCount
          };
        } else {
          throw new Error('Aucun contenu dans la r√©ponse Gemini');
        }
      } else {
        throw new Error('Aucune r√©ponse re√ßue de Gemini');
      }

    } catch (error: unknown) {
      logger.error('Erreur API Gemini', { error });
      throw error;
    }
  }

  /**
   * Cr√©er un prompt syst√®me pour ISSA
   */
  createSystemPrompt(userName?: string, knowledgeContext?: string): string {
    const basePrompt = `Tu es ISSA, l'assistant virtuel de ROI Takaful, entreprise sp√©cialis√©e en assurances islamiques.

INFORMATIONS SUR TOI :
- Tu es un assistant bienveillant, professionnel et chaleureux
- Tu repr√©sentes ROI Takaful, une entreprise d'assurances islamiques conformes √† la Charia
- ROI Takaful est une filiale de Royal Onyx Insurance (entreprise m√®re)
- Tu es sp√©cialis√© dans les assurances islamiques mais peux aussi renseigner sur Royal Onyx
- Tu communiques en fran√ßais et ton nom est ISSA

COMPORTEMENT ATTENDU :
- R√©ponds de mani√®re naturelle et conversationnelle, comme un humain
- Utilise le pr√©nom de l'utilisateur quand c'est appropri√©${userName ? ` (${userName})` : ''}
- Sois bienveillant, patient et √† l'√©coute
- Pose des questions de clarification si n√©cessaire

FORMATAGE IMPORTANT :
- N'utilise JAMAIS de Markdown (pas de *, **, #, ###, ‚Üí, ---, etc.)
- Utilise uniquement du texte simple avec des emojis
- Pour structurer : utilise des espaces, des retours √† la ligne et des emojis
- Exemple : ‚úÖ au lieu de *, üîπ pour les listes ou - pour faire plus naturel, üìç pour les points importants

R√àGLES STRICTES DE R√âPONSE :
üö® TR√àS IMPORTANT - R√àGLES ABSOLUES :
1. Tu DOIS EXCLUSIVEMENT utiliser les informations fournies dans "CONNAISSANCES DISPONIBLES" ci-dessous
2. Tu NE DOIS JAMAIS inventer, supposer ou extrapoler des informations
3. Si l'information n'est PAS dans les connaissances fournies, tu DOIS dire : "Je ne dispose pas de cette information dans ma base de connaissances actuelle"
4. Tu NE DOIS PAS donner d'informations g√©n√©rales ou suppos√©es m√™me si elles semblent logiques
5. SEULES les informations exactes de la base de connaissances peuvent √™tre utilis√©es

CONNAISSANCES DISPONIBLES :
${knowledgeContext || 'Aucune information sp√©cifique n\'est disponible pour cette requ√™te.'}

PROC√âDURE DE R√âPONSE :
1. V√©rifier si l'information demand√©e est dans les CONNAISSANCES DISPONIBLES
2. Si OUI : r√©pondre avec les informations exactes de la base
3. Si NON : dire "Je ne dispose pas de cette information" et rediriger vers :
   - www.roitakaful.com pour les questions ROI Takaful
   - www.royalonyx.cm pour les questions Royal Onyx Insurance
   - +237 691 100 575 pour le service client

INTERDICTIONS ABSOLUES :
‚ùå Ne jamais inventer de valeurs d'entreprise
‚ùå Ne jamais supposer des dates ou des chiffres
‚ùå Ne jamais donner d'informations "g√©n√©rales" sur l'assurance
‚ùå Ne jamais extrapoler au-del√† des connaissances fournies`;

    return basePrompt;
  }

  /**
   * Cr√©er un message de salutation personnalis√©
   */
  createGreetingMessage(userName?: string): string {
    if (userName) {
      // Messages de salutation quand on conna√Æt d√©j√† le nom
      const personalizedGreetings = [
        `Salam ${userName} üëã\nAlhamdulillah, quel plaisir de vous revoir !`,
        `Bonjour ${userName} ! üåü\nJe suis ravi de poursuivre notre conversation.`,
        `Assalam alaykum ${userName} üåô\nComment allez-vous aujourd'hui ?`
      ];
      return personalizedGreetings[Math.floor(Math.random() * personalizedGreetings.length)];
    }

    // Message de premi√®re salutation avec demande de nom (comme dans votre exemple)
    return `Salam üëã Je suis ISSA, votre compagnon digital chez ROI Takaful üåô.

Je suis l√† pour vous √©couter, vous guider et r√©pondre √† vos questions.

Avant de commencer, comment puis-je vous appeler ? ‚úçÔ∏è
(J'aime bien savoir avec qui je discute, √ßa rend la conversation plus conviviale üòâ)`;
  }

  /**
   * Cr√©er un message pour demander le nom (maintenant int√©gr√© dans createGreetingMessage)
   */
  createNameRequestMessage(): string {
    // Cette m√©thode est maintenant obsol√®te car le message de demande de nom
    // est int√©gr√© directement dans createGreetingMessage() pour correspondre √† votre exemple
    return "Comment puis-je vous appeler ?";
  }

  /**
   * Cr√©er le message de bienvenue personnalis√© apr√®s collecte du nom
   */
  createWelcomeAfterNameMessage(userName: string): string {
    return `Enchant√© ${userName} ü§ó !
Alhamdulillah, c'est un vrai plaisir de faire votre connaissance.
In sh√¢ All√¢h, je serai pour vous un compagnon utile et bienveillant tout au long de notre √©change.`;
  }

  /**
   * Cr√©er le message de suivi pour relancer naturellement la conversation
   */
  createFollowUpMessage(userName: string): string {
    return `Alors ${userName}, dites-moi, qu'aimeriez-vous aborder aujourd'hui ?
Vous pouvez poser votre question librement, je vous r√©ponds directement.`;
  }

  /**
   * G√©n√©rer un message de redirection vers le site web
   */
  createWebsiteRedirection(topic: string = "cette demande"): string {
    return `Pour ${topic}, je vous invite √† consulter notre site web pour des informations d√©taill√©es et √† jour :

üåê Site principal : www.royalonyx.cm
üïå ROI Takaful : www.roitakaful.com
üìû Service client : +237 691 100 575

Notre √©quipe sera ravie de vous accompagner personnellement !`;
  }

  /**
   * Valider la r√©ponse de l'IA pour s'assurer qu'elle respecte les r√®gles
   */
  private validateResponse(response: string, knowledgeContext: string): { isValid: boolean; reason?: string } {
    // Mots interdits qui indiquent une invention d'informations
    const forbiddenPhrases = [
      'g√©n√©ralement', 'habituellement', 'en g√©n√©ral', 'typiquement',
      'probablement', 'il est possible que', 'on peut supposer',
      'les valeurs sont souvent', 'comme la plupart des entreprises'
    ];

    // V√©rifier la pr√©sence de phrases interdites
    const responseLength = response.toLowerCase();
    for (const phrase of forbiddenPhrases) {
      if (responseLength.includes(phrase)) {
        return {
          isValid: false,
          reason: `R√©ponse contient une phrase interdite: "${phrase}"`
        };
      }
    }

    // Si pas de contexte de connaissances et que la r√©ponse est longue et d√©taill√©e
    if ((!knowledgeContext || knowledgeContext.includes('Aucune information sp√©cifique'))
        && response.length > 200 && !response.includes('Je ne dispose pas')) {
      return {
        isValid: false,
        reason: 'R√©ponse trop d√©taill√©e sans contexte de connaissances'
      };
    }

    return { isValid: true };
  }

  /**
   * Obtenir la configuration actuelle de l'IA
   */
  getConfig(): AIProviderConfig {
    return { ...this.aiConfig };
  }

  /**
   * Mettre √† jour la configuration de l'IA
   */
  updateConfig(newConfig: Partial<AIProviderConfig>): void {
    this.aiConfig = { ...this.aiConfig, ...newConfig };
    logger.info('Configuration IA mise √† jour', {
      provider: this.aiConfig.provider,
      model: this.aiConfig.model
    });
  }
}